{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "V8-yl-s-WKMG"
   },
   "source": [
    "# Object Detection Demo\n",
    "Welcome to the object detection inference walkthrough!  This notebook will walk you step by step through the process of using a pre-trained model to detect objects in an image. Make sure to follow the [installation instructions](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/installation.md) before you start."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kFSqkTCdWKMI"
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "hV4P5gyTWKMI"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0719 10:18:37.030103 140321098295104 __init__.py:308] Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import six.moves.urllib as urllib\n",
    "import sys\n",
    "import tarfile\n",
    "import tensorflow as tf\n",
    "import zipfile\n",
    "\n",
    "from distutils.version import StrictVersion\n",
    "from collections import defaultdict\n",
    "from io import StringIO\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "# This is needed since the notebook is stored in the object_detection folder.\n",
    "sys.path.append(\"..\")\n",
    "from object_detection.utils import ops as utils_ops\n",
    "\n",
    "if StrictVersion(tf.__version__) < StrictVersion('1.12.0'):\n",
    "  raise ImportError('Please upgrade your TensorFlow installation to v1.12.*.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'module://ipykernel.pylab.backend_inline'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.get_backend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Wy72mWwAWKMK"
   },
   "source": [
    "## Env setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "v7m_NY_aWKMK"
   },
   "outputs": [],
   "source": [
    "# This is needed to display the images.\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "r5FNuiRPWKMN"
   },
   "source": [
    "## Object detection imports\n",
    "Here are the imports from the object detection module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "bm0_uNRnWKMN"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'utils'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-aa270cd948af>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlabel_map_util\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mvisualization_utils\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mvis_util\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'utils'"
     ]
    }
   ],
   "source": [
    "from utils import label_map_util\n",
    "\n",
    "from utils import visualization_utils as vis_util"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cfn_tRFOWKMO"
   },
   "source": [
    "# Model preparation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "X_sEBLpVWKMQ"
   },
   "source": [
    "## Variables\n",
    "\n",
    "Any model exported using the `export_inference_graph.py` tool can be loaded here simply by changing `PATH_TO_FROZEN_GRAPH` to point to a new .pb file.  \n",
    "\n",
    "By default we use an \"SSD with Mobilenet\" model here. See the [detection model zoo](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md) for a list of other models that can be run out-of-the-box with varying speeds and accuracies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "VyPz_t8WWKMQ"
   },
   "outputs": [],
   "source": [
    "# What model to download.\n",
    "MODEL_NAME = 'training/model_graph'\n",
    "\n",
    "# Path to frozen detection graph. This is the actual model that is used for the object detection.\n",
    "PATH_TO_FROZEN_GRAPH = MODEL_NAME + '/frozen_inference_graph.pb'\n",
    "\n",
    "# List of the strings that is used to add correct label for each box.\n",
    "PATH_TO_LABELS = os.path.join('training', 'object-detection.pbtxt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7ai8pLZZWKMS"
   },
   "source": [
    "## Download Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YBcB9QHLWKMU"
   },
   "source": [
    "## Load a (frozen) Tensorflow model into memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "KezjCRVvWKMV"
   },
   "outputs": [],
   "source": [
    "detection_graph = tf.Graph()\n",
    "with detection_graph.as_default():\n",
    "    od_graph_def = tf.GraphDef()\n",
    "    with tf.gfile.GFile(PATH_TO_FROZEN_GRAPH, 'rb') as fid:\n",
    "        serialized_graph = fid.read()\n",
    "        od_graph_def.ParseFromString(serialized_graph)\n",
    "        tf.import_graph_def(od_graph_def, name='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_1MVVTcLWKMW"
   },
   "source": [
    "## Loading label map\n",
    "Label maps map indices to category names, so that when our convolution network predicts `5`, we know that this corresponds to `airplane`.  Here we use internal utility functions, but anything that returns a dictionary mapping integers to appropriate string labels would be fine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "hDbpHkiWWKMX"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0715 13:21:13.359763 139734831802176 deprecation_wrapper.py:119] From /home/maikyman/Documents/git/models/research/object_detection/utils/label_map_util.py:132: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "category_index = label_map_util.create_category_index_from_labelmap(PATH_TO_LABELS, use_display_name=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EFsoUHvbWKMZ"
   },
   "source": [
    "## Helper code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "aSlYc3JkWKMa"
   },
   "outputs": [],
   "source": [
    "def load_image_into_numpy_array(image):\n",
    "  (im_width, im_height) = image.size\n",
    "  return np.array(image.getdata()).reshape(\n",
    "      (im_height, im_width, 3)).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "H0_1AGhrWKMc"
   },
   "source": [
    "# Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "jG-zn5ykWKMd"
   },
   "outputs": [],
   "source": [
    "# For the sake of simplicity we will use only 2 images:\n",
    "# image1.jpg\n",
    "# image2.jpg\n",
    "# If you want to test the code with your images, just add path to the images to the TEST_IMAGE_PATHS.\n",
    "PATH_TO_TEST_IMAGES_DIR = 'test_images'\n",
    "TEST_IMAGE_PATHS = [ os.path.join(PATH_TO_TEST_IMAGES_DIR, 'image{}.jpg'.format(i)) for i in range(1, 3) ]\n",
    "\n",
    "# Size, in inches, of the output images.\n",
    "IMAGE_SIZE = (12, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "92BHxzcNWKMf"
   },
   "outputs": [],
   "source": [
    "def run_inference_for_single_image(image, graph):\n",
    "    with graph.as_default():\n",
    "        with tf.Session() as sess:\n",
    "            # Get handles to input and output tensors\n",
    "            ops = tf.get_default_graph().get_operations()\n",
    "            all_tensor_names = {output.name for op in ops for output in op.outputs}\n",
    "            tensor_dict = {}\n",
    "            for key in [\n",
    "              'num_detections', 'detection_boxes', 'detection_scores',\n",
    "              'detection_classes', 'detection_masks'\n",
    "            ]:\n",
    "                tensor_name = key + ':0'\n",
    "                if tensor_name in all_tensor_names:\n",
    "                    tensor_dict[key] = tf.get_default_graph().get_tensor_by_name(\n",
    "                      tensor_name)\n",
    "            if 'detection_masks' in tensor_dict:\n",
    "                # The following processing is only for single image\n",
    "                detection_boxes = tf.squeeze(tensor_dict['detection_boxes'], [0])\n",
    "                detection_masks = tf.squeeze(tensor_dict['detection_masks'], [0])\n",
    "                # Reframe is required to translate mask from box coordinates to image coordinates and fit the image size.\n",
    "                real_num_detection = tf.cast(tensor_dict['num_detections'][0], tf.int32)\n",
    "                detection_boxes = tf.slice(detection_boxes, [0, 0], [real_num_detection, -1])\n",
    "                detection_masks = tf.slice(detection_masks, [0, 0, 0], [real_num_detection, -1, -1])\n",
    "                detection_masks_reframed = utils_ops.reframe_box_masks_to_image_masks(\n",
    "                    detection_masks, detection_boxes, image.shape[1], image.shape[2])\n",
    "                detection_masks_reframed = tf.cast(\n",
    "                    tf.greater(detection_masks_reframed, 0.5), tf.uint8)\n",
    "                # Follow the convention by adding back the batch dimension\n",
    "                tensor_dict['detection_masks'] = tf.expand_dims(\n",
    "                    detection_masks_reframed, 0)\n",
    "            image_tensor = tf.get_default_graph().get_tensor_by_name('image_tensor:0')\n",
    "\n",
    "            # Run inference\n",
    "            output_dict = sess.run(tensor_dict,\n",
    "                                 feed_dict={image_tensor: image})\n",
    "\n",
    "            # all outputs are float32 numpy arrays, so convert types as appropriate\n",
    "            output_dict['num_detections'] = int(output_dict['num_detections'][0])\n",
    "            output_dict['detection_classes'] = output_dict[\n",
    "              'detection_classes'][0].astype(np.int64)\n",
    "            output_dict['detection_boxes'] = output_dict['detection_boxes'][0]\n",
    "            output_dict['detection_scores'] = output_dict['detection_scores'][0]\n",
    "            if 'detection_masks' in output_dict:\n",
    "                output_dict['detection_masks'] = output_dict['detection_masks'][0]\n",
    "    return output_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "3a5wMHN8WKMh"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.389737   0.03141874 0.56314594 0.20437329]\n",
      " [0.3533527  0.83985883 0.58585876 0.9841362 ]\n",
      " [0.17674337 0.16784102 0.9071804  0.8935126 ]\n",
      " [0.35199302 0.85830504 0.5127226  0.9927976 ]\n",
      " [0.34398612 0.8841469  0.4787268  1.        ]\n",
      " [0.49194622 0.9016943  0.96268874 0.9848481 ]\n",
      " [0.15789953 0.12739049 0.8193374  0.8978062 ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "images = []\n",
    "bbox = dict()\n",
    "PATH_TO_TEST_IMAGES_DIR = '/home/maikyman/Jupyter/PeopleRecognition/testImages/Images/'\n",
    "TEST_IMAGE_PATHS = [os.path.join(PATH_TO_TEST_IMAGES_DIR, '001cfa87e56b76a1.jpg'.format(0))] \n",
    "# TEST_IMAGE_PATHS = [ os.path.join(PATH_TO_TEST_IMAGES_DIR, 'frame{}.jpg'.format(i)) for i in range(149) ]\n",
    "for image_path in TEST_IMAGE_PATHS:\n",
    "    image = Image.open(image_path)\n",
    "    # the array based representation of the image will be used later in order to prepare the\n",
    "    # result image with boxes and labels on it.\n",
    "    image_np = load_image_into_numpy_array(image)\n",
    "    # Expand dimensions since the model expects images to have shape: [1, None, None, 3]\n",
    "    image_np_expanded = np.expand_dims(image_np, axis=0)\n",
    "    # Actual detection.\n",
    "    output_dict = run_inference_for_single_image(image_np_expanded, detection_graph)\n",
    "    \n",
    "#     print(output_dict['detection_scores'])\n",
    "    print(output_dict['detection_boxes'])\n",
    "    \n",
    "    # Visualization of the results of a detection.\n",
    "    vis_util.visualize_boxes_and_labels_on_image_array(\n",
    "      image_np,\n",
    "      output_dict['detection_boxes'],\n",
    "      output_dict['detection_classes'],\n",
    "      output_dict['detection_scores'],\n",
    "      category_index,\n",
    "      instance_masks=output_dict.get('detection_masks'),\n",
    "      use_normalized_coordinates=True,\n",
    "      line_thickness=4)\n",
    "    plt.figure(figsize=IMAGE_SIZE)\n",
    "    plt.imshow(image_np)\n",
    "    images.append(image_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "counter = 0\n",
    "for i in images:\n",
    "    Image.fromarray(i).save('/home/maikyman/Jupyter/PeopleRecognition/ImagePredictedResnet50/image_test%d.png' % counter)\n",
    "    counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "counter = 0\n",
    "for i in images:\n",
    "    Image.fromarray(i).save('image_test%d.png' % counter)\n",
    "    counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_IMAGE_PATH = [os.path.join(PATH_TO_TEST_IMAGES_DIR, '{}_frame.jpg'.format(0))] \n",
    "TEST_IMAGE_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "test = pd.read_csv('test_labels.csv')\n",
    "train = pd.read_csv('train_labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>class</th>\n",
       "      <th>xmin</th>\n",
       "      <th>ymin</th>\n",
       "      <th>xmax</th>\n",
       "      <th>ymax</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3cfe4a2c74ea128a.jpg</td>\n",
       "      <td>1024</td>\n",
       "      <td>768</td>\n",
       "      <td>person</td>\n",
       "      <td>883</td>\n",
       "      <td>247</td>\n",
       "      <td>1006</td>\n",
       "      <td>614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3cfe4a2c74ea128a.jpg</td>\n",
       "      <td>1024</td>\n",
       "      <td>768</td>\n",
       "      <td>person</td>\n",
       "      <td>606</td>\n",
       "      <td>200</td>\n",
       "      <td>713</td>\n",
       "      <td>569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3cfe4a2c74ea128a.jpg</td>\n",
       "      <td>1024</td>\n",
       "      <td>768</td>\n",
       "      <td>person</td>\n",
       "      <td>416</td>\n",
       "      <td>221</td>\n",
       "      <td>522</td>\n",
       "      <td>600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3cfe4a2c74ea128a.jpg</td>\n",
       "      <td>1024</td>\n",
       "      <td>768</td>\n",
       "      <td>person</td>\n",
       "      <td>227</td>\n",
       "      <td>225</td>\n",
       "      <td>301</td>\n",
       "      <td>527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3cfe4a2c74ea128a.jpg</td>\n",
       "      <td>1024</td>\n",
       "      <td>768</td>\n",
       "      <td>person</td>\n",
       "      <td>6</td>\n",
       "      <td>201</td>\n",
       "      <td>100</td>\n",
       "      <td>744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1a45d52ca17f13f3.jpg</td>\n",
       "      <td>1024</td>\n",
       "      <td>768</td>\n",
       "      <td>person</td>\n",
       "      <td>49</td>\n",
       "      <td>323</td>\n",
       "      <td>115</td>\n",
       "      <td>534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1a45d52ca17f13f3.jpg</td>\n",
       "      <td>1024</td>\n",
       "      <td>768</td>\n",
       "      <td>person</td>\n",
       "      <td>248</td>\n",
       "      <td>309</td>\n",
       "      <td>281</td>\n",
       "      <td>444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1a45d52ca17f13f3.jpg</td>\n",
       "      <td>1024</td>\n",
       "      <td>768</td>\n",
       "      <td>person</td>\n",
       "      <td>361</td>\n",
       "      <td>317</td>\n",
       "      <td>390</td>\n",
       "      <td>454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1a45d52ca17f13f3.jpg</td>\n",
       "      <td>1024</td>\n",
       "      <td>768</td>\n",
       "      <td>person</td>\n",
       "      <td>443</td>\n",
       "      <td>328</td>\n",
       "      <td>471</td>\n",
       "      <td>381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1a45d52ca17f13f3.jpg</td>\n",
       "      <td>1024</td>\n",
       "      <td>768</td>\n",
       "      <td>person</td>\n",
       "      <td>586</td>\n",
       "      <td>327</td>\n",
       "      <td>613</td>\n",
       "      <td>378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1a45d52ca17f13f3.jpg</td>\n",
       "      <td>1024</td>\n",
       "      <td>768</td>\n",
       "      <td>person</td>\n",
       "      <td>871</td>\n",
       "      <td>325</td>\n",
       "      <td>929</td>\n",
       "      <td>425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1a45d52ca17f13f3.jpg</td>\n",
       "      <td>1024</td>\n",
       "      <td>768</td>\n",
       "      <td>person</td>\n",
       "      <td>987</td>\n",
       "      <td>326</td>\n",
       "      <td>1024</td>\n",
       "      <td>436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1a45d52ca17f13f3.jpg</td>\n",
       "      <td>1024</td>\n",
       "      <td>768</td>\n",
       "      <td>person</td>\n",
       "      <td>148</td>\n",
       "      <td>328</td>\n",
       "      <td>171</td>\n",
       "      <td>380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1a45d52ca17f13f3.jpg</td>\n",
       "      <td>1024</td>\n",
       "      <td>768</td>\n",
       "      <td>person</td>\n",
       "      <td>516</td>\n",
       "      <td>333</td>\n",
       "      <td>536</td>\n",
       "      <td>372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1a45d52ca17f13f3.jpg</td>\n",
       "      <td>1024</td>\n",
       "      <td>768</td>\n",
       "      <td>person</td>\n",
       "      <td>790</td>\n",
       "      <td>307</td>\n",
       "      <td>838</td>\n",
       "      <td>417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2fbdd53f2dd692c3.jpg</td>\n",
       "      <td>973</td>\n",
       "      <td>1024</td>\n",
       "      <td>person</td>\n",
       "      <td>591</td>\n",
       "      <td>554</td>\n",
       "      <td>645</td>\n",
       "      <td>681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2fbdd53f2dd692c3.jpg</td>\n",
       "      <td>973</td>\n",
       "      <td>1024</td>\n",
       "      <td>person</td>\n",
       "      <td>883</td>\n",
       "      <td>524</td>\n",
       "      <td>948</td>\n",
       "      <td>685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2fbdd53f2dd692c3.jpg</td>\n",
       "      <td>973</td>\n",
       "      <td>1024</td>\n",
       "      <td>person</td>\n",
       "      <td>342</td>\n",
       "      <td>565</td>\n",
       "      <td>411</td>\n",
       "      <td>718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2fbdd53f2dd692c3.jpg</td>\n",
       "      <td>973</td>\n",
       "      <td>1024</td>\n",
       "      <td>person</td>\n",
       "      <td>280</td>\n",
       "      <td>564</td>\n",
       "      <td>335</td>\n",
       "      <td>704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2fbdd53f2dd692c3.jpg</td>\n",
       "      <td>973</td>\n",
       "      <td>1024</td>\n",
       "      <td>person</td>\n",
       "      <td>397</td>\n",
       "      <td>417</td>\n",
       "      <td>453</td>\n",
       "      <td>487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2fbdd53f2dd692c3.jpg</td>\n",
       "      <td>973</td>\n",
       "      <td>1024</td>\n",
       "      <td>person</td>\n",
       "      <td>21</td>\n",
       "      <td>516</td>\n",
       "      <td>80</td>\n",
       "      <td>744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2fbdd53f2dd692c3.jpg</td>\n",
       "      <td>973</td>\n",
       "      <td>1024</td>\n",
       "      <td>person</td>\n",
       "      <td>620</td>\n",
       "      <td>571</td>\n",
       "      <td>736</td>\n",
       "      <td>957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2fbdd53f2dd692c3.jpg</td>\n",
       "      <td>973</td>\n",
       "      <td>1024</td>\n",
       "      <td>person</td>\n",
       "      <td>59</td>\n",
       "      <td>95</td>\n",
       "      <td>98</td>\n",
       "      <td>161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2fbdd53f2dd692c3.jpg</td>\n",
       "      <td>973</td>\n",
       "      <td>1024</td>\n",
       "      <td>person</td>\n",
       "      <td>110</td>\n",
       "      <td>113</td>\n",
       "      <td>142</td>\n",
       "      <td>161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2fbdd53f2dd692c3.jpg</td>\n",
       "      <td>973</td>\n",
       "      <td>1024</td>\n",
       "      <td>person</td>\n",
       "      <td>195</td>\n",
       "      <td>90</td>\n",
       "      <td>236</td>\n",
       "      <td>134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2fbdd53f2dd692c3.jpg</td>\n",
       "      <td>973</td>\n",
       "      <td>1024</td>\n",
       "      <td>person</td>\n",
       "      <td>160</td>\n",
       "      <td>118</td>\n",
       "      <td>190</td>\n",
       "      <td>153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2fbdd53f2dd692c3.jpg</td>\n",
       "      <td>973</td>\n",
       "      <td>1024</td>\n",
       "      <td>person</td>\n",
       "      <td>726</td>\n",
       "      <td>90</td>\n",
       "      <td>768</td>\n",
       "      <td>160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2fbdd53f2dd692c3.jpg</td>\n",
       "      <td>973</td>\n",
       "      <td>1024</td>\n",
       "      <td>person</td>\n",
       "      <td>771</td>\n",
       "      <td>99</td>\n",
       "      <td>814</td>\n",
       "      <td>160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2fbdd53f2dd692c3.jpg</td>\n",
       "      <td>973</td>\n",
       "      <td>1024</td>\n",
       "      <td>person</td>\n",
       "      <td>817</td>\n",
       "      <td>91</td>\n",
       "      <td>868</td>\n",
       "      <td>156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2fbdd53f2dd692c3.jpg</td>\n",
       "      <td>973</td>\n",
       "      <td>1024</td>\n",
       "      <td>person</td>\n",
       "      <td>77</td>\n",
       "      <td>34</td>\n",
       "      <td>867</td>\n",
       "      <td>379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1254</th>\n",
       "      <td>2f4ded5c1dcc1b38.jpg</td>\n",
       "      <td>1024</td>\n",
       "      <td>388</td>\n",
       "      <td>person</td>\n",
       "      <td>669</td>\n",
       "      <td>229</td>\n",
       "      <td>684</td>\n",
       "      <td>285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1255</th>\n",
       "      <td>2f4ded5c1dcc1b38.jpg</td>\n",
       "      <td>1024</td>\n",
       "      <td>388</td>\n",
       "      <td>person</td>\n",
       "      <td>688</td>\n",
       "      <td>229</td>\n",
       "      <td>700</td>\n",
       "      <td>290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1256</th>\n",
       "      <td>2f4ded5c1dcc1b38.jpg</td>\n",
       "      <td>1024</td>\n",
       "      <td>388</td>\n",
       "      <td>person</td>\n",
       "      <td>701</td>\n",
       "      <td>230</td>\n",
       "      <td>713</td>\n",
       "      <td>282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1257</th>\n",
       "      <td>2f4ded5c1dcc1b38.jpg</td>\n",
       "      <td>1024</td>\n",
       "      <td>388</td>\n",
       "      <td>person</td>\n",
       "      <td>619</td>\n",
       "      <td>220</td>\n",
       "      <td>640</td>\n",
       "      <td>290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1258</th>\n",
       "      <td>2f4ded5c1dcc1b38.jpg</td>\n",
       "      <td>1024</td>\n",
       "      <td>388</td>\n",
       "      <td>person</td>\n",
       "      <td>569</td>\n",
       "      <td>220</td>\n",
       "      <td>593</td>\n",
       "      <td>288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1259</th>\n",
       "      <td>2f4ded5c1dcc1b38.jpg</td>\n",
       "      <td>1024</td>\n",
       "      <td>388</td>\n",
       "      <td>person</td>\n",
       "      <td>518</td>\n",
       "      <td>223</td>\n",
       "      <td>544</td>\n",
       "      <td>286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1260</th>\n",
       "      <td>2f4ded5c1dcc1b38.jpg</td>\n",
       "      <td>1024</td>\n",
       "      <td>388</td>\n",
       "      <td>person</td>\n",
       "      <td>485</td>\n",
       "      <td>224</td>\n",
       "      <td>508</td>\n",
       "      <td>289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1261</th>\n",
       "      <td>2f4ded5c1dcc1b38.jpg</td>\n",
       "      <td>1024</td>\n",
       "      <td>388</td>\n",
       "      <td>person</td>\n",
       "      <td>331</td>\n",
       "      <td>234</td>\n",
       "      <td>358</td>\n",
       "      <td>299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1262</th>\n",
       "      <td>2f4ded5c1dcc1b38.jpg</td>\n",
       "      <td>1024</td>\n",
       "      <td>388</td>\n",
       "      <td>person</td>\n",
       "      <td>353</td>\n",
       "      <td>216</td>\n",
       "      <td>378</td>\n",
       "      <td>281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1263</th>\n",
       "      <td>2f4ded5c1dcc1b38.jpg</td>\n",
       "      <td>1024</td>\n",
       "      <td>388</td>\n",
       "      <td>person</td>\n",
       "      <td>215</td>\n",
       "      <td>222</td>\n",
       "      <td>234</td>\n",
       "      <td>280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1264</th>\n",
       "      <td>2f4ded5c1dcc1b38.jpg</td>\n",
       "      <td>1024</td>\n",
       "      <td>388</td>\n",
       "      <td>person</td>\n",
       "      <td>184</td>\n",
       "      <td>214</td>\n",
       "      <td>200</td>\n",
       "      <td>281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1265</th>\n",
       "      <td>2f4ded5c1dcc1b38.jpg</td>\n",
       "      <td>1024</td>\n",
       "      <td>388</td>\n",
       "      <td>person</td>\n",
       "      <td>146</td>\n",
       "      <td>224</td>\n",
       "      <td>161</td>\n",
       "      <td>283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1266</th>\n",
       "      <td>2f4ded5c1dcc1b38.jpg</td>\n",
       "      <td>1024</td>\n",
       "      <td>388</td>\n",
       "      <td>person</td>\n",
       "      <td>118</td>\n",
       "      <td>218</td>\n",
       "      <td>135</td>\n",
       "      <td>285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1267</th>\n",
       "      <td>2f4ded5c1dcc1b38.jpg</td>\n",
       "      <td>1024</td>\n",
       "      <td>388</td>\n",
       "      <td>person</td>\n",
       "      <td>82</td>\n",
       "      <td>217</td>\n",
       "      <td>99</td>\n",
       "      <td>286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1268</th>\n",
       "      <td>2f4ded5c1dcc1b38.jpg</td>\n",
       "      <td>1024</td>\n",
       "      <td>388</td>\n",
       "      <td>person</td>\n",
       "      <td>63</td>\n",
       "      <td>212</td>\n",
       "      <td>78</td>\n",
       "      <td>275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1269</th>\n",
       "      <td>2f4ded5c1dcc1b38.jpg</td>\n",
       "      <td>1024</td>\n",
       "      <td>388</td>\n",
       "      <td>person</td>\n",
       "      <td>35</td>\n",
       "      <td>216</td>\n",
       "      <td>53</td>\n",
       "      <td>273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1270</th>\n",
       "      <td>3be3093a9799d45a.jpg</td>\n",
       "      <td>1024</td>\n",
       "      <td>683</td>\n",
       "      <td>person</td>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>228</td>\n",
       "      <td>647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1271</th>\n",
       "      <td>3be3093a9799d45a.jpg</td>\n",
       "      <td>1024</td>\n",
       "      <td>683</td>\n",
       "      <td>person</td>\n",
       "      <td>697</td>\n",
       "      <td>174</td>\n",
       "      <td>831</td>\n",
       "      <td>606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1272</th>\n",
       "      <td>3be3093a9799d45a.jpg</td>\n",
       "      <td>1024</td>\n",
       "      <td>683</td>\n",
       "      <td>person</td>\n",
       "      <td>554</td>\n",
       "      <td>212</td>\n",
       "      <td>669</td>\n",
       "      <td>417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1273</th>\n",
       "      <td>3be3093a9799d45a.jpg</td>\n",
       "      <td>1024</td>\n",
       "      <td>683</td>\n",
       "      <td>person</td>\n",
       "      <td>847</td>\n",
       "      <td>234</td>\n",
       "      <td>903</td>\n",
       "      <td>377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1274</th>\n",
       "      <td>3be3093a9799d45a.jpg</td>\n",
       "      <td>1024</td>\n",
       "      <td>683</td>\n",
       "      <td>person</td>\n",
       "      <td>901</td>\n",
       "      <td>234</td>\n",
       "      <td>948</td>\n",
       "      <td>317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1275</th>\n",
       "      <td>3be3093a9799d45a.jpg</td>\n",
       "      <td>1024</td>\n",
       "      <td>683</td>\n",
       "      <td>person</td>\n",
       "      <td>951</td>\n",
       "      <td>240</td>\n",
       "      <td>982</td>\n",
       "      <td>297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1276</th>\n",
       "      <td>3be3093a9799d45a.jpg</td>\n",
       "      <td>1024</td>\n",
       "      <td>683</td>\n",
       "      <td>person</td>\n",
       "      <td>984</td>\n",
       "      <td>240</td>\n",
       "      <td>1022</td>\n",
       "      <td>362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1277</th>\n",
       "      <td>2ebead5fd59d9709.jpg</td>\n",
       "      <td>680</td>\n",
       "      <td>1024</td>\n",
       "      <td>person</td>\n",
       "      <td>354</td>\n",
       "      <td>122</td>\n",
       "      <td>507</td>\n",
       "      <td>320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1278</th>\n",
       "      <td>2ebead5fd59d9709.jpg</td>\n",
       "      <td>680</td>\n",
       "      <td>1024</td>\n",
       "      <td>person</td>\n",
       "      <td>214</td>\n",
       "      <td>194</td>\n",
       "      <td>337</td>\n",
       "      <td>396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1279</th>\n",
       "      <td>2ebead5fd59d9709.jpg</td>\n",
       "      <td>680</td>\n",
       "      <td>1024</td>\n",
       "      <td>person</td>\n",
       "      <td>375</td>\n",
       "      <td>484</td>\n",
       "      <td>491</td>\n",
       "      <td>698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1280</th>\n",
       "      <td>2ebead5fd59d9709.jpg</td>\n",
       "      <td>680</td>\n",
       "      <td>1024</td>\n",
       "      <td>person</td>\n",
       "      <td>258</td>\n",
       "      <td>429</td>\n",
       "      <td>372</td>\n",
       "      <td>566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1281</th>\n",
       "      <td>2ebead5fd59d9709.jpg</td>\n",
       "      <td>680</td>\n",
       "      <td>1024</td>\n",
       "      <td>person</td>\n",
       "      <td>225</td>\n",
       "      <td>49</td>\n",
       "      <td>351</td>\n",
       "      <td>194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1282</th>\n",
       "      <td>0e4d09844e0568f2.jpg</td>\n",
       "      <td>1024</td>\n",
       "      <td>685</td>\n",
       "      <td>person</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>299</td>\n",
       "      <td>670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1283</th>\n",
       "      <td>0e4d09844e0568f2.jpg</td>\n",
       "      <td>1024</td>\n",
       "      <td>685</td>\n",
       "      <td>person</td>\n",
       "      <td>364</td>\n",
       "      <td>114</td>\n",
       "      <td>805</td>\n",
       "      <td>604</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1284 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  filename  width  height   class  xmin  ymin  xmax  ymax\n",
       "0     3cfe4a2c74ea128a.jpg   1024     768  person   883   247  1006   614\n",
       "1     3cfe4a2c74ea128a.jpg   1024     768  person   606   200   713   569\n",
       "2     3cfe4a2c74ea128a.jpg   1024     768  person   416   221   522   600\n",
       "3     3cfe4a2c74ea128a.jpg   1024     768  person   227   225   301   527\n",
       "4     3cfe4a2c74ea128a.jpg   1024     768  person     6   201   100   744\n",
       "5     1a45d52ca17f13f3.jpg   1024     768  person    49   323   115   534\n",
       "6     1a45d52ca17f13f3.jpg   1024     768  person   248   309   281   444\n",
       "7     1a45d52ca17f13f3.jpg   1024     768  person   361   317   390   454\n",
       "8     1a45d52ca17f13f3.jpg   1024     768  person   443   328   471   381\n",
       "9     1a45d52ca17f13f3.jpg   1024     768  person   586   327   613   378\n",
       "10    1a45d52ca17f13f3.jpg   1024     768  person   871   325   929   425\n",
       "11    1a45d52ca17f13f3.jpg   1024     768  person   987   326  1024   436\n",
       "12    1a45d52ca17f13f3.jpg   1024     768  person   148   328   171   380\n",
       "13    1a45d52ca17f13f3.jpg   1024     768  person   516   333   536   372\n",
       "14    1a45d52ca17f13f3.jpg   1024     768  person   790   307   838   417\n",
       "15    2fbdd53f2dd692c3.jpg    973    1024  person   591   554   645   681\n",
       "16    2fbdd53f2dd692c3.jpg    973    1024  person   883   524   948   685\n",
       "17    2fbdd53f2dd692c3.jpg    973    1024  person   342   565   411   718\n",
       "18    2fbdd53f2dd692c3.jpg    973    1024  person   280   564   335   704\n",
       "19    2fbdd53f2dd692c3.jpg    973    1024  person   397   417   453   487\n",
       "20    2fbdd53f2dd692c3.jpg    973    1024  person    21   516    80   744\n",
       "21    2fbdd53f2dd692c3.jpg    973    1024  person   620   571   736   957\n",
       "22    2fbdd53f2dd692c3.jpg    973    1024  person    59    95    98   161\n",
       "23    2fbdd53f2dd692c3.jpg    973    1024  person   110   113   142   161\n",
       "24    2fbdd53f2dd692c3.jpg    973    1024  person   195    90   236   134\n",
       "25    2fbdd53f2dd692c3.jpg    973    1024  person   160   118   190   153\n",
       "26    2fbdd53f2dd692c3.jpg    973    1024  person   726    90   768   160\n",
       "27    2fbdd53f2dd692c3.jpg    973    1024  person   771    99   814   160\n",
       "28    2fbdd53f2dd692c3.jpg    973    1024  person   817    91   868   156\n",
       "29    2fbdd53f2dd692c3.jpg    973    1024  person    77    34   867   379\n",
       "...                    ...    ...     ...     ...   ...   ...   ...   ...\n",
       "1254  2f4ded5c1dcc1b38.jpg   1024     388  person   669   229   684   285\n",
       "1255  2f4ded5c1dcc1b38.jpg   1024     388  person   688   229   700   290\n",
       "1256  2f4ded5c1dcc1b38.jpg   1024     388  person   701   230   713   282\n",
       "1257  2f4ded5c1dcc1b38.jpg   1024     388  person   619   220   640   290\n",
       "1258  2f4ded5c1dcc1b38.jpg   1024     388  person   569   220   593   288\n",
       "1259  2f4ded5c1dcc1b38.jpg   1024     388  person   518   223   544   286\n",
       "1260  2f4ded5c1dcc1b38.jpg   1024     388  person   485   224   508   289\n",
       "1261  2f4ded5c1dcc1b38.jpg   1024     388  person   331   234   358   299\n",
       "1262  2f4ded5c1dcc1b38.jpg   1024     388  person   353   216   378   281\n",
       "1263  2f4ded5c1dcc1b38.jpg   1024     388  person   215   222   234   280\n",
       "1264  2f4ded5c1dcc1b38.jpg   1024     388  person   184   214   200   281\n",
       "1265  2f4ded5c1dcc1b38.jpg   1024     388  person   146   224   161   283\n",
       "1266  2f4ded5c1dcc1b38.jpg   1024     388  person   118   218   135   285\n",
       "1267  2f4ded5c1dcc1b38.jpg   1024     388  person    82   217    99   286\n",
       "1268  2f4ded5c1dcc1b38.jpg   1024     388  person    63   212    78   275\n",
       "1269  2f4ded5c1dcc1b38.jpg   1024     388  person    35   216    53   273\n",
       "1270  3be3093a9799d45a.jpg   1024     683  person     1    89   228   647\n",
       "1271  3be3093a9799d45a.jpg   1024     683  person   697   174   831   606\n",
       "1272  3be3093a9799d45a.jpg   1024     683  person   554   212   669   417\n",
       "1273  3be3093a9799d45a.jpg   1024     683  person   847   234   903   377\n",
       "1274  3be3093a9799d45a.jpg   1024     683  person   901   234   948   317\n",
       "1275  3be3093a9799d45a.jpg   1024     683  person   951   240   982   297\n",
       "1276  3be3093a9799d45a.jpg   1024     683  person   984   240  1022   362\n",
       "1277  2ebead5fd59d9709.jpg    680    1024  person   354   122   507   320\n",
       "1278  2ebead5fd59d9709.jpg    680    1024  person   214   194   337   396\n",
       "1279  2ebead5fd59d9709.jpg    680    1024  person   375   484   491   698\n",
       "1280  2ebead5fd59d9709.jpg    680    1024  person   258   429   372   566\n",
       "1281  2ebead5fd59d9709.jpg    680    1024  person   225    49   351   194\n",
       "1282  0e4d09844e0568f2.jpg   1024     685  person     1     8   299   670\n",
       "1283  0e4d09844e0568f2.jpg   1024     685  person   364   114   805   604\n",
       "\n",
       "[1284 rows x 8 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df = test.append(train)\n",
    "final_df.index = [i for i in range(len(final_df))]\n",
    "final_df"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "default_view": {},
   "name": "object_detection_tutorial.ipynb?workspaceId=ronnyvotel:python_inference::citc",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
